{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Assignment 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url= \"https://www.google.com/search?q=gini+index+formula&tbm=isch&ved=2ahUKEwj2xp_hmsrsAhXDMN8KHTurCn0Q2-cCegQIABAA&oq=gini+index+formula&gs_lcp=CgNpbWcQAzICCAAyAggAMgIIADIGCAAQBRAeMgQIABAYMgQIABAYMgQIABAYMgQIABAYMgQIABAYOgYIABAIEB5Qvw9YtRpgwBtoAHAAeAGAAcIBiAHHBZIBAzYuMZgBAKABAaoBC2d3cy13aXotaW1nwAEB&sclient=img&ei=jYiSX7bMOcPh_Aa71qroBw&bih=689&biw=630#imgrc=ICbn8krtgakNkM\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Binary Classification: \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Processing:\n",
    "\n",
    "### a) Import the data: shape should be (30000,24)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default payment next month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3272</td>\n",
       "      <td>3455</td>\n",
       "      <td>3261</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14331</td>\n",
       "      <td>14948</td>\n",
       "      <td>15549</td>\n",
       "      <td>1518</td>\n",
       "      <td>1500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>28314</td>\n",
       "      <td>28959</td>\n",
       "      <td>29547</td>\n",
       "      <td>2000</td>\n",
       "      <td>2019</td>\n",
       "      <td>1200</td>\n",
       "      <td>1100</td>\n",
       "      <td>1069</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20940</td>\n",
       "      <td>19146</td>\n",
       "      <td>19131</td>\n",
       "      <td>2000</td>\n",
       "      <td>36681</td>\n",
       "      <td>10000</td>\n",
       "      <td>9000</td>\n",
       "      <td>689</td>\n",
       "      <td>679</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
       "0      20000    2          2         1   24      2      2     -1     -1   \n",
       "1     120000    2          2         2   26     -1      2      0      0   \n",
       "2      90000    2          2         2   34      0      0      0      0   \n",
       "3      50000    2          2         1   37      0      0      0      0   \n",
       "4      50000    1          2         1   57     -1      0     -1      0   \n",
       "\n",
       "   PAY_5  ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
       "0     -2  ...          0          0          0         0       689         0   \n",
       "1      0  ...       3272       3455       3261         0      1000      1000   \n",
       "2      0  ...      14331      14948      15549      1518      1500      1000   \n",
       "3      0  ...      28314      28959      29547      2000      2019      1200   \n",
       "4      0  ...      20940      19146      19131      2000     36681     10000   \n",
       "\n",
       "   PAY_AMT4  PAY_AMT5  PAY_AMT6  default payment next month  \n",
       "0         0         0         0                           1  \n",
       "1      1000         0      2000                           1  \n",
       "2      1000      1000      5000                           0  \n",
       "3      1100      1069      1000                           0  \n",
       "4      9000       689       679                           0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"default of credit card clients.csv\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 24)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Remove any rows that have missing data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIMIT_BAL                     0\n",
      "SEX                           0\n",
      "EDUCATION                     0\n",
      "MARRIAGE                      0\n",
      "AGE                           0\n",
      "PAY_0                         0\n",
      "PAY_2                         0\n",
      "PAY_3                         0\n",
      "PAY_4                         0\n",
      "PAY_5                         0\n",
      "PAY_6                         0\n",
      "BILL_AMT1                     0\n",
      "BILL_AMT2                     0\n",
      "BILL_AMT3                     0\n",
      "BILL_AMT4                     0\n",
      "BILL_AMT5                     0\n",
      "BILL_AMT6                     0\n",
      "PAY_AMT1                      0\n",
      "PAY_AMT2                      0\n",
      "PAY_AMT3                      0\n",
      "PAY_AMT4                      0\n",
      "PAY_AMT5                      0\n",
      "PAY_AMT6                      0\n",
      "default payment next month    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Checking for missing data\n",
    "print(dataset.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Based on the above results we can observe that there aren't any missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### c) The target / y variable is \"default payment next month\" column. Keep all predictors for the X df except for the target variable. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:,0:23]\n",
    "y = dataset.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### d) Split data into train / test set using an 70/30 split. Recall that you should be generating an X_train, X_test, y_train, and y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Random Forest Classifier - Base Model:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start by creating a simple Random Forest only using default parameters.\n",
    "\n",
    "### a) Use the RandomForestClassifier in sklearn. Fit your model on the training data & make sure to add a random_state (check documentation to confirm how to do this). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=20)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate a random forests classifer\n",
    "rf = RandomForestClassifier(random_state=20)\n",
    "# Fitting the data to the data\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Use the fitted model to predict on test data. Use the .predict_proba() and the .predict() methods to get predicted probabilities as well as predicted classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted probabilities using .predict_proba()\n",
    "y_pred_prob = rf.predict_proba(X_test)\n",
    "# predicted classes using .predict()\n",
    "y_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Calculate the confusion matrix and classification report (both are in sklearn.metrics). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6598,  384],\n",
       "       [1285,  733]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confusion matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the confusion matrix we can infer that True Positives are 6632; True Negatives are 733; False Negatives  are 1285 and our False Positives 408"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89      6982\n",
      "           1       0.66      0.36      0.47      2018\n",
      "\n",
      "    accuracy                           0.81      9000\n",
      "   macro avg       0.75      0.65      0.68      9000\n",
      "weighted avg       0.80      0.81      0.79      9000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the report following are the metrics:\n",
    "- Precision - 0.84 for non-default and .66 for default\n",
    "- F1 Score -  0.89 for non-default and  .47 for default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Calculate the roc_auc_score for this model. There are many ways to do this, but an example is to use the probabilities from step B and utilize the roc_auc_score from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23469010217126357\n"
     ]
    }
   ],
   "source": [
    "# calculating roc_auc_score for our target class = 1\n",
    "print(roc_auc_score(y_test, y_pred_prob[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7653109979250056\n"
     ]
    }
   ],
   "source": [
    "# calculating roc_auc_score for our target class = 0\n",
    "print(roc_auc_score(y_test, y_pred_prob[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The roc_auc score for our target class '0' has a score which of 0.76\n",
    "\n",
    "- For the target class '1'. We have a score of 0.23. \n",
    "\n",
    "- Based on the above values we can infer that the model was able to better classify the non-default data when compared to default class data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e) Calculate predictions for the training data & build the classification report & roc_auc_score. Are there signs of overfitting? Why or why not?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = rf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     16382\n",
      "           1       1.00      1.00      1.00      4618\n",
      "\n",
      "    accuracy                           1.00     21000\n",
      "   macro avg       1.00      1.00      1.00     21000\n",
      "weighted avg       1.00      1.00      1.00     21000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classification report for our predicted classes and our y_test\n",
    "print(classification_report(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the precision, recall and accuracy values we can say that the values represent a clear scenario of overfitting. The model was able to learn perfectly about the train data as well as the noise and hence the overfit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9992449909768504\n"
     ]
    }
   ],
   "source": [
    "#roc_auc_score for our complete target class\n",
    "print(roc_auc_score(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6541161769795132\n"
     ]
    }
   ],
   "source": [
    "# roc_auc_score for our complete target class\n",
    "print(roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The roc_auc_score of the train data is significantly greater than the test data. This signifies that the model is overfittinga"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the classification report and roc_auc_score signify that the model is prone to overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Random Forest Classifier - Grid Search\n",
    "### a) Use the RandomForestClassifier along with the GridSearchCV tool. Run the GridSearchCV using the following:\n",
    "- ######  n_estimators: 50, 100, 500  \n",
    "- ######  max_features: 2, 4, sqrt  \n",
    "- ###### max_depth: 6, 8, 10, 12  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_estimators': [50, 100, 500],\n",
    "'max_features': [2,4,6],\n",
    "'max_depth':[6,8,10,12]}\n",
    "\n",
    "# create Random Forest model \n",
    "rf=RandomForestClassifier()\n",
    "\n",
    "# Use 5 cross-fold and for scoring use \"roc_auc\" \n",
    "rf_Grid = GridSearchCV(rf, param_grid, cv = 5, scoring = 'roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "             param_grid={'max_depth': [6, 8, 10, 12], 'max_features': [2, 4, 6],\n",
       "                         'n_estimators': [50, 100, 500]},\n",
       "             scoring='roc_auc')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit our model to our train data\n",
    "rf_Grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Identify the best performing model:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 12, 'max_features': 2, 'n_estimators': 500}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To identify the best performing parameters\n",
    "rf_Grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=12, max_features=2, n_estimators=500)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To identify the best performing model\n",
    "rf_Grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Use the best estimator model to predict on test data. Use the .predict_proba() and the .predict() methods to get predicted probabilities as well as predicted classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  .predict() to get predicted classes.\n",
    "y_pred_grid = rf_Grid.predict(X_test)\n",
    "y_pred_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.94100636, 0.05899364],\n",
       "       [0.59656722, 0.40343278],\n",
       "       [0.92893567, 0.07106433],\n",
       "       ...,\n",
       "       [0.94848926, 0.05151074],\n",
       "       [0.50037639, 0.49962361],\n",
       "       [0.86905653, 0.13094347]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# .predict_proba() to get predicted probabilities.\n",
    "y_predprob_grid = rf_Grid.predict_proba(X_test)\n",
    "y_predprob_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Calculate the confusion matrix and classification report (both are in sklearn.metrics).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89      6982\n",
      "           1       0.70      0.32      0.44      2018\n",
      "\n",
      "    accuracy                           0.82      9000\n",
      "   macro avg       0.76      0.64      0.67      9000\n",
      "weighted avg       0.80      0.82      0.79      9000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification_report_score\n",
    "print(classification_report(y_test, y_pred_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6697,  285],\n",
       "       [1366,  652]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion_matrix\n",
    "confusion_matrix(y_test, y_pred_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the confusion matrix we can infer that True Positives are 6697; True Negatives are 652; False Negatives  are 1366 and our False Positives 285"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e) Calculate the roc_auc_score for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6411364604835483\n"
     ]
    }
   ],
   "source": [
    "# roc_auc_score for model with GridSearch\n",
    "print(roc_auc_score(y_test, y_pred_grid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The roc_auc_score is 64.1%, the score is similar to the roc_auc_score of the model with default parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f) Calculate predictions for the training data & build the confusion matrix, classification report & roc_auc_score. Are there signs of overfitting? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting the train error score\n",
    "y_pred_train_grid = rf_Grid.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.93     16382\n",
      "           1       0.92      0.48      0.63      4618\n",
      "\n",
      "    accuracy                           0.88     21000\n",
      "   macro avg       0.90      0.73      0.78     21000\n",
      "weighted avg       0.88      0.88      0.86     21000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification report\n",
    "print(classification_report(y_train, y_pred_train_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16189,   193],\n",
       "       [ 2401,  2217]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion_matrix for our predicted and actual train target class\n",
    "confusion_matrix(y_train, y_pred_train_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7341483662655867\n"
     ]
    }
   ],
   "source": [
    "# roc_auc_score for predicted and actual train target class\n",
    "print(roc_auc_score(y_train, y_pred_train_grid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the comparison of the test and train scores\n",
    "\n",
    "ROC - Test ROC - 0.64 , Train ROC - 0.73\n",
    "\n",
    "Based on the ROC values we can see that there isn't siginificant difference between the ROC values. So, we can infer that there isn't any ovefit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create a feature importance plot for your best performing model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) What are the top 5 features for this model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Random Forest model with out best parameters that we got using GridSearch in Part 3 \n",
    "rf_best = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "                       max_depth=12, max_features=2, max_leaf_nodes=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=1, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
    "                       n_jobs=None, oob_score=False, random_state=None,\n",
    "                       verbose=0, warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=12, max_features=2, n_estimators=500)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit our model to our train data\n",
    "rf_best.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0419753 , 0.00715437, 0.01319083, 0.00853985, 0.03393656,\n",
       "       0.17589184, 0.08523078, 0.05976649, 0.04056441, 0.04306667,\n",
       "       0.03447943, 0.04277195, 0.04076055, 0.03834458, 0.03807294,\n",
       "       0.03623988, 0.03650993, 0.04563772, 0.03929279, 0.03815829,\n",
       "       0.03391373, 0.03284616, 0.03365496])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the important features deemed by the model\n",
    "rf_best.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['LIMIT_BAL', 'SEX', 'EDUCATION', 'MARRIAGE', 'AGE', 'PAY_0', 'PAY_2',\n",
       "       'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6', 'BILL_AMT1', 'BILL_AMT2',\n",
       "       'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1',\n",
       "       'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assigning the column names\n",
    "features = X_train.columns\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Barplot to plot the features according to the importance\n",
    "\n",
    "importance = rf_best.feature_importances_\n",
    "indices = np.argsort(importance)\n",
    "plt.title('Variable feature importance')\n",
    "plt.barh(range(len(indices)), importance[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the feature importance plot the best features are\n",
    "- PAY_0\n",
    "- PAY_2\n",
    "- PAY_3\n",
    "- PAY_AMT1\n",
    "- PAY 5\n",
    "- BILL_AMT1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conceptual Questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) What are the best parameters from the Grid Search in Question # 3? Does the Model from #3 outperform Model #2? Explain why."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best parameters from the Grid Search are:\n",
    "\n",
    "                   (bootstrap=True, class_weight=None, criterion='gini',\n",
    "                   max_depth=12, max_features=2, max_leaf_nodes=None,\n",
    "                   min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                   min_samples_leaf=1, min_samples_split=2,\n",
    "                   min_weight_fraction_leaf=0.0, n_estimators=500,\n",
    "                   n_jobs=None, oob_score=False, random_state=None,\n",
    "                   verbose=0, warm_start=False)\n",
    "\n",
    "Based on the model metrics we can clearly state that the model from question #3 has outperformed the model in question #2. Also, the model in question #2 is heavily prone to overfitting while the model in question #3 is optimal for predicting the class of the target variable.\n",
    "This model performance can also be contributed towards finding the best parameters using Gridsearch. The initial model was trained using the default parameters and has hence contributed towards overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Overfitting is always a concern in ML problems. Does Model #3 overfit data more or less than Model #2? Explain why you think this is the case.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model #3 does not overfit the data as compared to model # 2 , the reason being model # 2 was on the features with default parameters, model # 3 was trained using the optimal parameters that we had idenitified using GridSearch, also we have used k-fold cross-validation while determining the optimal hyperparameters. Additionally, we've also compared the ROC_AUC scores of both training and test data sets and based on the scores we can conclude that the Model #2 is more prone to overfitting compared to Model #3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) The lecture notes describe the Gini Index which is the default criterion used for splitting in sklearn's version of RandomForestClassifier. How does the Gini Index work? (i.e. How is it used to build a top-performing model?)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gini Index or Gini impurity, calculates the probability of a particular variable that is classified incorrectly when selected randomly. If all the elements of a variable belong to a single classs, then it can be termed as pure. \n",
    "\n",
    "\n",
    "The Gini index varies between values 0 and 1, where 0 imples that all the elements belong to a single class and 1 implies that the elements are randomly distributed across various classes. Gini Index of 0.5 imples that there's a equal distribution of the classes.\n",
    "\n",
    "In theory, the top-performing model is built in such a way that features across the data have least Gene Index associated with them. Following is the formula of the gini index.\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/415/0*asbVp_8lwEsbfpOv.png\" width=200 height=200 />\n",
    "\n",
    "\n",
    "The Gini Index is calculated by deducting the sum of square of the probabilities of each class from one. Where Pi is the probability of an object bring classified to a particular class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Describe how Random Forest is different from bagging & why this difference can yield improved results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagging is generally used to create samples of data when there isn't sufficient data present. The new dataset are created by sampling the data samples from the original dataset. The bootstrap method involves iteratively resampling a dataset with replacement.\n",
    "\n",
    "One of the main advantages of use bagging is that it reduces variance of the model and while using bagging along with decision trees it's highly suggested to use deep decision trees because of high variance and low bias.\n",
    "\n",
    "On the other hand Random forest can be described as generalized form of bagging. At each of the branches of the decision tree, Random Forest training involves subsampling of the features in addition to the training examples. Also, subsampling of the features removes corrleation between the features amongst the individual trees, which is better than Bagging.\n",
    "\n",
    "The main difference is that in Random forests, only a subset of features are selected at random out of the total and the best split feature from the subset is used to split each node in a tree, unlike in bagging where all features are considered for splitting a node. Due to the random feature selection, the trees are more independent of each other compared to regular bagging, which often results in better predictive performance (due to better variance-bias trade-offs), and random forest is faster than bagging, because each tree learns only from a subset of features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e) Describe the importance of the max_depth parameter in Random Forest. Do not just provide a definition, rather think through how bias-variance tradeoff might be impacted by the max_depth parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max_depth is, represents the depth of each tree in the random forest. The deeper the treem the more the splits it has and the more information it captures about the data.\n",
    "\n",
    "A max_depth of 20 would limit trees at most 20 splits down on any given branch. In practise as the max depth of the decision tree increases, the performance of the model over the training set increases continuously. On the other hand as the max_depth value increases, the performance over the test set increases initially but after a certain point, it starts to decrease rapidly. The reason being,tree starts to overfit the training set and therefore is not able to generalize over the unseen points in the test set.\n",
    "\n",
    "Alternatively, severely constraining max_depth could increase the bias of each tree. It may not be able to capture certain patterns in the data.However, this can be resolved by a suitable choice of n_estimators, coupled with bagging, ensures that the bias of the forest as a whole doesnâ€™t increase in the process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f) In this homework we used k-fold cross-validation while determining the optimal hyperparameters for our Random Forest model. 1) Describe how k-fold cross-validation works. 2) What benefit do we gain by using k-fold cross-validation when tuning our Random Forest model versus only using the train-test split approach?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k-Fold cross validation approach involves random divison of the observation into k groups/folds, where each fold is used as a test set at some point.\n",
    "\n",
    "In case of 5-fold cross validation the data set is split into 5 folds. In the first iteration, the first fold is used to test the model and the rest are used to train the model. In the second iteration, 2nd fold is used as the testing set while the rest serve as the training set. This process is repeated until each fold of the 5 folds have been used as the testing set.\n",
    "\n",
    "The advantage of using the k-fold cross validation versus train-test split approach while tuning a Random Forest model is that cross-validation necessitates the model to train on multiple train-test splits rather than a single instance of train data. Training on multiple splits of data gives the model a better indication of the data and will accordingly perform well on unseen data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
