{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Assignment 8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jk-TD73bEZjy"
   },
   "source": [
    "## 1. Data Processing:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "rHZ6T8dMEZjy"
   },
   "outputs": [],
   "source": [
    "# a) Import the following libraries:\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import pandas\n",
    "import numpy\n",
    "import optparse\n",
    "\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import LSTM, Dense, Dropout, SimpleRNN\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from collections import OrderedDict\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot\n",
    "%matplotlib inline\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z3B0xFN2Eg9w",
    "outputId": "98abe1be-4d6c-4e6b-f94d-6c7a64693901"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "id": "kLE6bIoHEZjy",
    "outputId": "14262b9e-1813-48bc-a249-0dbb8b5ea1ba"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{\"timestamp\":1502738402847,\"method\":\"post\",\"qu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{\"timestamp\":1502738402849,\"method\":\"post\",\"qu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{\"timestamp\":1502738402852,\"method\":\"post\",\"qu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{\"timestamp\":1502738402852,\"method\":\"post\",\"qu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{\"timestamp\":1502738402853,\"method\":\"post\",\"qu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  1\n",
       "0  {\"timestamp\":1502738402847,\"method\":\"post\",\"qu...  0\n",
       "1  {\"timestamp\":1502738402849,\"method\":\"post\",\"qu...  0\n",
       "2  {\"timestamp\":1502738402852,\"method\":\"post\",\"qu...  0\n",
       "3  {\"timestamp\":1502738402852,\"method\":\"post\",\"qu...  0\n",
       "4  {\"timestamp\":1502738402853,\"method\":\"post\",\"qu...  0"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# b) lets import the data\n",
    "dataset = pd.read_csv(\"/content/drive/My Drive/Assignment/dev-access.csv\", engine='python', quotechar='|', header=None)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "hRVs0idpEZjz"
   },
   "outputs": [],
   "source": [
    "# c) We then need to convert to a numpy.ndarray type: \n",
    "dataset = dataset.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XQPqwMNBEZjz",
    "outputId": "e58566cd-e8cc-45ad-ca58-7fd3786d6920"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26773, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# d) lets check the shape of our data, it should be (26773, 2).\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sjGOXoHcEZjz",
    "outputId": "122bc88e-e256-4c2d-f98c-e2ebc16a0a99"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['{\"timestamp\":1502738402847,\"method\":\"post\",\"query\":{},\"path\":\"/login\",\"statusCode\":401,\"source\":{\"remoteAddress\":\"88.141.113.237\",\"referer\":\"http://localhost:8002/enter\"},\"route\":\"/login\",\"headers\":{\"host\":\"localhost:8002\",\"accept-language\":\"en-us\",\"accept-encoding\":\"gzip, deflate\",\"connection\":\"keep-alive\",\"accept\":\"*/*\",\"referer\":\"http://localhost:8002/enter\",\"cache-control\":\"no-cache\",\"x-requested-with\":\"XMLHttpRequest\",\"content-type\":\"application/json\",\"content-length\":\"36\"},\"requestPayload\":{\"username\":\"Carl2\",\"password\":\"bo\"},\"responsePayload\":{\"statusCode\":401,\"error\":\"Unauthorized\",\"message\":\"Invalid Login\"}}',\n",
       "        0],\n",
       "       ['{\"timestamp\":1502738402849,\"method\":\"post\",\"query\":{},\"path\":\"/login\",\"statusCode\":401,\"source\":{\"remoteAddress\":\"88.141.113.237\"},\"route\":\"/login\",\"headers\":{\"host\":\"localhost:8002\",\"connection\":\"keep-alive\",\"cache-control\":\"no-cache\",\"accept\":\"*/*\",\"accept-encoding\":\"gzip, deflate, br\",\"accept-language\":\"en-US,en;q=0.8,es;q=0.6\",\"content-type\":\"application/json\",\"content-length\":\"47\"},\"requestPayload\":{\"username\":\"pafzah\",\"password\":\"worldburn432\"},\"responsePayload\":{\"statusCode\":401,\"error\":\"Unauthorized\",\"message\":\"Invalid Login\"}}',\n",
       "        0],\n",
       "       ['{\"timestamp\":1502738402852,\"method\":\"post\",\"query\":{},\"path\":\"/login\",\"statusCode\":401,\"source\":{\"remoteAddress\":\"205.49.83.118\"},\"route\":\"/login\",\"headers\":{\"host\":\"localhost:8002\",\"connection\":\"keep-alive\",\"cache-control\":\"no-cache\",\"accept\":\"*/*\",\"accept-encoding\":\"gzip, deflate, br\",\"accept-language\":\"en-US,en;q=0.8,es;q=0.6\",\"content-type\":\"application/json\",\"content-length\":\"44\"},\"requestPayload\":{\"username\":\"Panos1\",\"password\":\"najrijkom\"},\"responsePayload\":{\"statusCode\":401,\"error\":\"Unauthorized\",\"message\":\"Invalid Login\"}}',\n",
       "        0],\n",
       "       ...,\n",
       "       ['{\"timestamp\":1502738800390,\"method\":\"post\",\"query\":{},\"path\":\"/checkout\",\"statusCode\":400,\"source\":{\"remoteAddress\":\"233.150.201.166\"},\"route\":\"/checkout\",\"headers\":{\"host\":\"localhost:8002\",\"connection\":\"keep-alive\",\"cache-control\":\"no-cache\",\"accept\":\"*/*\",\"accept-encoding\":\"gzip, deflate, br\",\"accept-language\":\"en-US,en;q=0.8,es;q=0.6\",\"content-type\":\"application/json\",\"content-length\":\"80\"},\"requestPayload\":{\"creditCard\":\"<script src=\\\\\"http://attacker/malicious‑script.js\\\\\"></script>\"},\"responsePayload\":{\"statusCode\":400,\"error\":\"Bad Request\",\"message\":\"Bad Request\"}}',\n",
       "        1],\n",
       "       ['{\"timestamp\":1502738803362,\"method\":\"post\",\"query\":{},\"path\":\"/checkout\",\"statusCode\":400,\"source\":{\"remoteAddress\":\"182.239.131.78\",\"referer\":\"http://localhost:8002/enter\"},\"route\":\"/checkout\",\"headers\":{\"host\":\"localhost:8002\",\"connection\":\"keep-alive\",\"accept\":\"*/*\",\"cache-control\":\"no-cache\",\"x-requested-with\":\"XMLHttpRequest\",\"referer\":\"http://localhost:8002/enter\",\"accept-encoding\":\"gzip, deflate, br\",\"accept-language\":\"en-US,en;q=0.8,es;q=0.6\",\"content-type\":\"application/json\",\"content-length\":\"46\"},\"requestPayload\":{\"creditCard\":\"<meta http-equiv=\\\\\"refresh\\\\\">\"},\"responsePayload\":{\"statusCode\":400,\"error\":\"Bad Request\",\"message\":\"Bad Request\"}}',\n",
       "        1],\n",
       "       ['{\"timestamp\":1502738810082,\"method\":\"post\",\"query\":{},\"path\":\"/checkout\",\"statusCode\":400,\"source\":{\"remoteAddress\":\"182.239.131.78\"},\"route\":\"/checkout\",\"headers\":{\"host\":\"localhost:8002\",\"connection\":\"keep-alive\",\"cache-control\":\"no-cache\",\"accept\":\"*/*\",\"accept-encoding\":\"gzip, deflate, br\",\"accept-language\":\"en-US,en;q=0.8,es;q=0.6\",\"content-type\":\"application/json\",\"content-length\":\"46\"},\"requestPayload\":{\"creditCard\":\"<meta http-equiv=\\\\\"refresh\\\\\">\"},\"responsePayload\":{\"statusCode\":400,\"error\":\"Bad Request\",\"message\":\"Bad Request\"}}',\n",
       "        1]], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "CRtGUhfqEZjz"
   },
   "outputs": [],
   "source": [
    "#e) Store all rows and the 0th index as the feature data:\n",
    "X = dataset[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U0sfFhxzEZjz",
    "outputId": "75926bf5-7df2-40d9-e8ee-f36b17501212"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#f) Store all rows and index 1 as the target variable: \n",
    "Y = dataset[:,1]\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Vd-RAlzoEZjz"
   },
   "outputs": [],
   "source": [
    "#g) we will clean our data, and remove unwanted variables, which are timestamp, headers, source, route, responsePayload\n",
    "for index, item in enumerate(X):\n",
    "    # Quick hack to space out json elements\n",
    "    reqJson = json.loads(item, object_pairs_hook=OrderedDict)\n",
    "    del reqJson['timestamp']\n",
    "    del reqJson['headers']\n",
    "    del reqJson['source']\n",
    "    del reqJson['route']\n",
    "    del reqJson['responsePayload']\n",
    "    X[index] = json.dumps(reqJson, separators=(',', ':'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "aaHHld84EZjz"
   },
   "outputs": [],
   "source": [
    "#h) We next will tokenize our data, which just means vectorizing our text.\n",
    "tokenizer = Tokenizer(filters='\\t\\n', char_level=True)\n",
    "tokenizer.fit_on_texts(X)\n",
    "\n",
    "num_words = len(tokenizer.word_index)+1\n",
    "X = tokenizer.texts_to_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Yje8VAN8EZjz"
   },
   "outputs": [],
   "source": [
    "#i) Need to pad our data as each observation has a different length\n",
    "max_log_length = 1024\n",
    "X_processed = sequence.pad_sequences(X, maxlen=max_log_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "YDClVlNJEZjz"
   },
   "outputs": [],
   "source": [
    "# j) Create your train set to be 75% of the data and your test set to be 25\n",
    "from sklearn.model_selection import train_test_split\n",
    "#---Splitting the data into train and test----#\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_processed, Y, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WoNwo4dMEZjz"
   },
   "source": [
    "## 2. Model 1 - RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "qDbAMVUvEZjz"
   },
   "outputs": [],
   "source": [
    "#a) Initialising the RNN\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "VAKqnkCDEZj0"
   },
   "outputs": [],
   "source": [
    "# b) add an Embedding Layer\n",
    "# c) add a SimpleRNN layer\n",
    "# d) add a Dense layer\n",
    "\n",
    "\n",
    "classifier.add(Embedding(num_words, 32, input_length=max_log_length))\n",
    "classifier.add(SimpleRNN(units = 32,activation=\"relu\"))\n",
    "classifier.add(Dense(units=1, activation = \"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "ldH1GwU7EZj0"
   },
   "outputs": [],
   "source": [
    "# e) lets compile the model\n",
    "classifier.compile(optimizer = 'adam', metrics = ['accuracy'], loss = 'binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g3WafNmaEZj0",
    "outputId": "4ca4d3e2-3aaf-4746-f34e-098b520398dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 1024, 32)          2016      \n",
      "_________________________________________________________________\n",
      "simple_rnn (SimpleRNN)       (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 4,129\n",
      "Trainable params: 4,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# f) model summary\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "MkbOOPhjEZj0"
   },
   "outputs": [],
   "source": [
    "# Converting the X_train and y_train to float otherwise the model.fit gives error\n",
    "X_train = np.asarray(X_train).astype(np.float32)\n",
    "y_train = np.asarray(y_train).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FrqX7n2mEZj0",
    "outputId": "6eb001a6-d7a6-494a-fb28-5b1d77b8a779"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "118/118 [==============================] - 37s 313ms/step - loss: 7.7437 - accuracy: 0.4980 - val_loss: 7.7709 - val_accuracy: 0.4962\n",
      "Epoch 2/3\n",
      "118/118 [==============================] - 37s 312ms/step - loss: 7.7437 - accuracy: 0.4980 - val_loss: 7.7709 - val_accuracy: 0.4962\n",
      "Epoch 3/3\n",
      "118/118 [==============================] - 37s 310ms/step - loss: 7.7437 - accuracy: 0.4980 - val_loss: 7.7709 - val_accuracy: 0.4962\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f3b18bf3dd8>"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# g) Fitting the RNN to the Training set\n",
    "classifier.fit(X_train, y_train, validation_split = 0.25, epochs = 3, batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "vBu8oolmEZj0"
   },
   "outputs": [],
   "source": [
    "# Converting the X_test and y_test to float otherwise the model.fit gives error\n",
    "X_test = np.asarray(X_train).astype(np.float32)\n",
    "y_test = np.asarray(y_train).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oRI1f3JuEZj0",
    "outputId": "f077a988-ac81-4132-888e-05d376f0cf57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 11s 68ms/step - loss: 7.7505 - accuracy: 0.4975\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[7.750502109527588, 0.49753475189208984]"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# h) Use the .evaluate() method to get the loss value & the accuracy value on the test data. \n",
    "classifier.evaluate(X_test, y_test, batch_size = 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I348UZTeEZj0"
   },
   "source": [
    "## 3) Model 2 - LSTM + Dropout Layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "WqvXQhBTEZj0"
   },
   "outputs": [],
   "source": [
    "# a)Initialising the RNN\n",
    "classifier_LSTM = Sequential()\n",
    "#add an Embedding Layer \n",
    "classifier_LSTM.add(Embedding(num_words, 32, input_length=max_log_length))\n",
    "#Adding the first LSTM layer and some Dropout regularisation\n",
    "classifier_LSTM.add(LSTM(units = 64, recurrent_dropout = 0.5))\n",
    "classifier_LSTM.add(Dropout(0.5))\n",
    "#add a Dense layer\n",
    "classifier_LSTM.add(Dense(units=1, activation = \"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "z1lkMf0ZEZj0"
   },
   "outputs": [],
   "source": [
    "#b)Compiling the RNN\n",
    "classifier_LSTM.compile(optimizer = 'adam', metrics = [\"accuracy\"], loss = 'binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yUt_NqWuEZj0",
    "outputId": "e4f09817-f920-4aab-9c15-e2f08687c2d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 1024, 32)          2016      \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 64)                24832     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 26,913\n",
      "Trainable params: 26,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#c)Model summary\n",
    "classifier_LSTM.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XEbacQMQEZj1",
    "outputId": "41466fae-be42-40e6-ab4c-c2f287a6fb71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "118/118 [==============================] - 226s 2s/step - loss: 0.8538 - accuracy: 0.5379 - val_loss: 0.5465 - val_accuracy: 0.6697\n",
      "Epoch 2/3\n",
      "118/118 [==============================] - 231s 2s/step - loss: 0.4721 - accuracy: 0.8177 - val_loss: 0.2585 - val_accuracy: 0.9382\n",
      "Epoch 3/3\n",
      "118/118 [==============================] - 225s 2s/step - loss: 0.2651 - accuracy: 0.9325 - val_loss: 0.2187 - val_accuracy: 0.9090\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f3b1636acf8>"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#d)Use the .fit() method to fit the model on the train data. Use a validation split of 0.25, epochs=3 and batch size = 128.\n",
    "classifier_LSTM.fit(X_train, y_train, validation_split = 0.25, epochs = 3, batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V4Mi3i04EZj1",
    "outputId": "b5c4c012-86fc-4117-f512-44e663201b4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 50s 316ms/step - loss: 0.2366 - accuracy: 0.9044\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.23663170635700226, 0.9044275283813477]"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#e)Use the .evaluate() method to get the loss value & the accuracy value on the test data. \n",
    "classifier_LSTM.evaluate(X_test, y_test, batch_size = 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lhN1DRetEZj1"
   },
   "source": [
    "## 4) Recurrent Neural Net Model 3: Build Your Own"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sB0ZazsWEZj1"
   },
   "source": [
    "### a) RNN Requirements\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "zUBZzQTbEZj1"
   },
   "outputs": [],
   "source": [
    "# Initialising the RNN\n",
    "custom_classifier = Sequential()\n",
    "# add an Embedding Layer \n",
    "custom_classifier.add(Embedding(num_words, 32, input_length=max_log_length))\n",
    "# Adding the first LSTM layer and some Dropout regularisation\n",
    "custom_classifier.add(LSTM(units = 128, recurrent_dropout = 0.5, return_sequences=True))\n",
    "custom_classifier.add(Dropout(0.25))\n",
    "# Adding the first LSTM layer and some Dropout regularisation\n",
    "custom_classifier.add(LSTM(units = 64, recurrent_dropout = 0.5, return_sequences=True))\n",
    "custom_classifier.add(Dropout(0.25))\n",
    "# Adding a second LSTM layer and some Dropout regularisation\n",
    "custom_classifier.add(LSTM(units = 64, recurrent_dropout = 0.5, return_sequences=False))\n",
    "custom_classifier.add(Dropout(0.5))\n",
    "# add a Dense layer\n",
    "custom_classifier.add(Dense(units=1, activation = \"relu\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "coLKqrf_EZj1"
   },
   "source": [
    "### b) Compiler Requirements\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "u5PW3XX7EZj1"
   },
   "outputs": [],
   "source": [
    "#stochastic gradient descent as the optimizer for this model\n",
    "custom_classifier.compile(optimizer = 'SGD', metrics = ['accuracy'], loss = 'binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4f0rccT0EZj1"
   },
   "source": [
    "### c) Print the model summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RyCBZL6yEZj1",
    "outputId": "899f08dc-9a6d-4e12-b261-36f423a19530"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 1024, 32)          2016      \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 1024, 128)         82432     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024, 128)         0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 1024, 64)          49408     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024, 64)          0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 166,945\n",
      "Trainable params: 166,945\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "custom_classifier.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GdCpoT_TEZj1"
   },
   "source": [
    "### d) Use the .fit() method to fit the model on the train data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NHfGS6tjEZj1",
    "outputId": "a627028b-9650-4bfd-e226-9c80c5d0d048"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "118/118 [==============================] - 1097s 9s/step - loss: 7.5668 - accuracy: 0.5026 - val_loss: 7.5669 - val_accuracy: 0.5038\n",
      "Epoch 2/3\n",
      "118/118 [==============================] - 1098s 9s/step - loss: 7.5937 - accuracy: 0.5020 - val_loss: 7.5669 - val_accuracy: 0.5038\n",
      "Epoch 3/3\n",
      "118/118 [==============================] - 1098s 9s/step - loss: 7.5937 - accuracy: 0.5020 - val_loss: 7.5669 - val_accuracy: 0.5038\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f3b14b84978>"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use a validation split of 0.25, epochs=3 and batch size = 128.\n",
    "custom_classifier.fit(X_train, y_train, validation_split = 0.25, epochs = 3, batch_size = 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U08hIqsJEZj1"
   },
   "source": [
    "### e) Use the .evaluate() method to get the loss value & the accuracy value on the test data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6c65T3_CEZj1",
    "outputId": "f0e0a21f-b8bf-46de-8cd7-ce44c3392951"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 212s 1s/step - loss: 7.5870 - accuracy: 0.5025\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[7.587025165557861, 0.5024652481079102]"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate on the test data with a batch size of 128 \n",
    "custom_classifier.evaluate(X_test, y_test, batch_size = 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uUTYYDpOEZj1"
   },
   "source": [
    "## Conceptual Questions:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9DotoSodEZj1"
   },
   "source": [
    "#### 5) Explain the difference between the relu activation function and the sigmoid activation function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D-QZPlq6EZj1"
   },
   "source": [
    "###### Sigmoid function\n",
    "The Sigmoid Function curve looks like a S-shape.\n",
    "\n",
    "   <img src = \"Screen Shot 2020-12-03 at 6.14.16 PM.png\" width=\"400\">\n",
    "\n",
    "The sigmoid function exists between (0 to 1). Therefore, it is especially used for models where we have to predict the probability as an output.Since probability of anything exists only between the range of 0 and 1, sigmoid is the right choice.The function is differentiable.That means, we can find the slope of the sigmoid curve at any two points. The function is monotonic but function’s derivative is not.The logistic sigmoid function can cause a neural network to get stuck at the training time.\n",
    "\n",
    "\n",
    "###### ReLU (Rectified Linear Unit) Activation Function\n",
    "\n",
    "   <img src = \"Screen Shot 2020-12-03 at 6.14.53 PM.png\" width=\"300\">\n",
    "    \n",
    "The ReLU is the most used activation function in the world right now.Since, it is used in almost all the convolutional neural networks or deep learning.\n",
    "\n",
    "As you can see, the ReLU is half rectified (from bottom). f(z) is zero when z is less than zero and f(z) is equal to z when z is above or equal to zero.\n",
    "\n",
    "Range: [0 to infinity)\n",
    "\n",
    "The function and its derivative both are monotonic.\n",
    "But the issue is that all the negative values become zero immediately which decreases the ability of the model to fit or train from the data properly. That means any negative input given to the ReLU activation function turns the value into zero immediately in the graph, which in turns affects the resulting graph by not mapping the negative values appropriately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "44-uMS_WEZj1"
   },
   "source": [
    "#### 6) Describe what one epoch actually is (epoch was a parameter used in the .fit() method).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of epochs is a hyperparameter that defines the number times that the learning algorithm will work through the entire training dataset.\n",
    "\n",
    "One epoch means that each sample in the training dataset has had an opportunity to update the internal model parameters. An epoch is comprised of one or more batches. For example, as above, an epoch that has one batch is called the batch gradient descent learning algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7) Explain how dropout works (you can look at the keras code and/or documentation) for (a) training, and (b) test data sets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropout is a regularization method that approximates training a large number of neural networks with different architectures in parallel.\n",
    "\n",
    "During training, for each hidden layer, for each training sample, for each iteration, ignore a random fraction, p, number of nodes and corresponding activations. Dropout changed the concept of learning all the weights together, to learning a fraction of the weights in the network in each training iteration.This means that their contribution to the activation of downstream neurons is temporally removed on the forward pass and any weight updates are not applied to the neuron on the backward pass. This prevents units from co-adapting too much. \n",
    "\n",
    "In the testing phase, dropout uses all all activations, but reduces them by a factor p, to account for the missing activations during training. The reason why we scale the weights w by p during the testing phase is because the expected value of a Dropout network is equivalent to a regular network with its weights scaled with the Dropout rate p. The scaling makes the inferences from a Dropout network comparable to the full network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8) Explain why problems such as this homework assignment are better modeled with RNNs than CNNs. What type of problem will CNNs outperform RNNs on?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason why the homework assignment is better modeled with RNN than CNN is because of Recurrent Neural Networks(RNN). RNNs and LSTMs by design are most suitable for working with seuqence prediction problems. The reason being, the ability to process temporal information or data that comes in sequences, such as a sentence for example. And on other hand, CNNs defining feature is that it performs the convolution operation in certain layers – hence, the name Convolutional Neural Network.\n",
    "\n",
    "The Convolutional Neural Networks, or CNNs, CNNs are great at interpreting visual data and data that does not come in a sequence. However, they fail in interpreting temporal information such as videos (which are essentially a sequence of individual images) and blocks of text. The benefit of using CNNs is their ability to develop an internal representation of a two-dimensional image. This allows the model to learn position and scale in variant structures in the data, which is important when working with images.\n",
    "\n",
    "To summarize, RNN is used for sequential data cases, and CNNs for interpreting visual data and data that does not come in a sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9) Explain what RNN problem is solved using LSTM and briefly describe how.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNNs enable modelling time-dependent and sequential data tasks, such as stock market prediction, machine translation, text generation and many more.\n",
    "\n",
    "RNNs suffer from the problem of vanishing gradients, which hampers learning of long data sequences. The gradients carry information used in the RNN parameter update and when the gradient becomes smaller and smaller, the parameter updates become insignificant which means no real learning is done.\n",
    "\n",
    "LSTMs solve the problem using a unique additive gradient structure that includes direct access to the forget gate’s activations, enabling the network to encourage desired behaviour from the error gradient using frequent gates update on every time step of the learning process. \n",
    "LSTMs use a series of ‘gates’ which control how the information in a sequence of data comes into, is stored in and leaves the network. There are three gates in a typical LSTM; forget gate, input gate and output gate. These gates can be thought of as filters and are each their own neural network. We will explore them all in detail during the course of this article.\n",
    "-  The forget gate controls what information in the cell state to forget, given new information than entered the network\n",
    "- The input gate controls what new information will be encoded into the cell state, given the new input information\n",
    "- The output gate controls what information encoded in the cell state is sent to the network as input in the following time step\n",
    "\n",
    "    <img src = \"Screen Shot 2020-12-03 at 7.36.20 PM.png\" width=\"300\">\n",
    "\n",
    "In RNNs, the sum in the above equation is made from expressions with a similar behaviour that are likely to all be in [0,1] which causes vanishing gradients.\n",
    " \n",
    "In LSTMs, however, the presence of the forget gate, along with the additive property of the cell state gradients, enables the network to update the parameter in such a way that the different sub gradients in the above equation do not necessarily agree and behave in a similar manner, making it less likely that all of the T gradients will vanish, or in other words, the series of functions does not converge to zero.\n",
    " \n",
    " \n",
    "To summarize, RNNs suffer from vanishing gradients and caused by long series of multiplications of small values, diminishing the gradients and causing the learning process to become degenerate.RNNs suffer from exploding gradients affected from large gradient values and hampering the learning process.\n",
    "LSTMs solve the problem using a unique additive gradient structure that includes direct access to the forget gate’s activations, enabling the network to encourage desired behaviour from the error gradient using frequent gates update on every time step of the learning process.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "9DotoSodEZj1"
   ],
   "name": "MachineLearning_Assignment8_Bharadwaj.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
